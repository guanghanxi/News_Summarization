{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c487177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk.tokenize\n",
    "import re\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c430c3e",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8977213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pack_sequence, pad_packed_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b793f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    text_data = []\n",
    "    target_data = []\n",
    "    for unit in data:\n",
    "        text_data.append(torch.tensor(unit[0]))\n",
    "        target_data.append(torch.tensor(unit[1]))\n",
    "    text = pad_sequence(text_data, batch_first=True)\n",
    "    target = pad_sequence(target_data, batch_first=True)\n",
    "    return text, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cf71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_path = \"LSTM_test_data/test_data_loader.pth\"\n",
    "vocab_path = \"LSTM_test_data/text_vocab.pth\"\n",
    "test_data_loader = torch.load(loader_path)\n",
    "text_vocab = torch.load(vocab_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f168b9",
   "metadata": {},
   "source": [
    "BiLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb23c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, dec_hidden_dim, num_layers,dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_dim=input_dim\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.num_layers=num_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, dec_hidden_dim)\n",
    "\n",
    "        self.layer=nn.LSTM(input_size=emb_dim,hidden_size=hidden_dim, \\\n",
    "                        num_layers=num_layers,batch_first=True, \\\n",
    "                        dropout=dropout,bidirectional=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(x))     \n",
    "        \n",
    "        out,(hidden,c)=self.layer(embedded)\n",
    "        \n",
    "        s = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
    "        \n",
    "        return out, s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb55de",
   "metadata": {},
   "source": [
    "Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9337e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        # [size(h_t)+size(s_{t-1}), dec_hid_dim]\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim, bias=False)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, s, enc_output):\n",
    "        # s = [batch_size, dec_hid_dim]\n",
    "        # enc_output = [batch_size, src_len, enc_hid_dim * 2]\n",
    "\n",
    "        batch_size = enc_output.shape[0]\n",
    "        src_len = enc_output.shape[1]\n",
    "\n",
    "        # repeat decoder hidden state src_len times\n",
    "        # s = [batch_size, src_len, enc_hid_dim * 2]\n",
    "        # enc_output = [batch_size, src_len, enc_hid_dim * 2]\n",
    "        s = s.unsqueeze(1).repeat(1, src_len, 1)\n",
    "\n",
    "        # energy = [batch_size, src_len, dec_hid_dim]\n",
    "        energy = torch.tanh(self.attn(torch.cat((s, enc_output), dim=2)))\n",
    "\n",
    "        # attention = [batch_size, src_len]\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec77278",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention, device):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.device = device\n",
    "        \n",
    "        self.layer=nn.LSTM(input_size=enc_hid_dim * 2 + emb_dim, hidden_size=dec_hid_dim, \\\n",
    "                        num_layers=1,batch_first=True, \\\n",
    "                        dropout=dropout,bidirectional=False)\n",
    "        \n",
    "        self.fc_out = nn.Linear(enc_hid_dim * 2 + dec_hid_dim + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, dec_input, s, enc_output):\n",
    "        # dec_input = [batch_size]\n",
    "        # s = [batch_size, dec_hid_dim]\n",
    "        # enc_output = [src_len, batch_size, enc_hid_dim *2]\n",
    "        \n",
    "        batch_size = dec_input.shape[0]\n",
    "\n",
    "        # dec_input = [batch_size,1]\n",
    "        dec_input = dec_input.unsqueeze(1)\n",
    "\n",
    "        # embedded = [batch_size, 1, emb_dim]\n",
    "        embedded = self.dropout(self.embedding(dec_input))\n",
    "\n",
    "        # s = [batch_size, dec_hid_dim]\n",
    "        # enc_output = [batch_size, src_len, enc_hid_dim *2]\n",
    "\n",
    "        # a = [batch_size, 1, src_len]\n",
    "        a = self.attention(s, enc_output).unsqueeze(1)\n",
    "\n",
    "        # c = [batch_size, 1, enc_hid_dim * 2]\n",
    "        c = torch.bmm(a, enc_output)\n",
    "\n",
    "        # lstm_input = [batch_size, 1, (enc_hid_dim*2) + emb_dim]\n",
    "        lstm_input = torch.cat((embedded, c), dim=2)\n",
    "        \n",
    "        c0 = torch.randn(1, batch_size, self.dec_hid_dim).to(self.device)\n",
    "\n",
    "        # dec_output = [batch_size, src_len(=1), dec_hid_dim]\n",
    "        # dec_hidden = [n_layers*num_directions, batch_size, dec_hid_dim]\n",
    "        dec_output, (dec_hidden, _) = self.layer(lstm_input, (s.unsqueeze(0), c0))\n",
    "\n",
    "        # embedded = [batch_size, emb_dim]\n",
    "        # dec_output = [batch_size, dec_hid_dim]\n",
    "        # c = [batch_size, enc_hid_dim * 2]\n",
    "        embedded = embedded.squeeze(1)\n",
    "        dec_output = dec_output.squeeze(1)\n",
    "        c = c.squeeze(1)\n",
    "\n",
    "        # pred = [batch_size, output_dim]\n",
    "        pred = self.fc_out(torch.cat((dec_output, c, embedded), dim=1))\n",
    "\n",
    "        return pred, dec_hidden.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dbbf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src = [batch_size, text_length]\n",
    "        # trg = [batch_size, summarizarion_length]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing (scheduled sampling)\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, vocab_size).to(self.device)\n",
    "\n",
    "        # enc_output : [src_len, batch_size, enc_hid_dim * 2]\n",
    "        # s : [batch_size, dec_hid_dim]\n",
    "        enc_output, s = self.encoder(src)\n",
    "\n",
    "        # first input to the decoder is the <bob> tokens\n",
    "        dec_input = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            dec_output, s = self.decoder(dec_input, s, enc_output)\n",
    "\n",
    "            outputs[t] = dec_output\n",
    "\n",
    "            # decide if using teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # get the highest predicted token from predictions\n",
    "            prediction = dec_output.argmax(1)\n",
    "\n",
    "            # if teacher forcing, use actural next token as input\n",
    "            # if not, use predicted token\n",
    "            dec_input = trg[:, t] if teacher_force else prediction\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf6f27ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Define Hyper parameter\n",
    "\n",
    "INPUT_DIM = len(text_vocab)\n",
    "OUTPUT_DIM = len(text_vocab)\n",
    "ENC_EMB_DIM = 300\n",
    "DEC_EMB_DIM = 300\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, 2, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn, device)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852602b9",
   "metadata": {},
   "source": [
    "### Reload a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e3bcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = 'LSTM_model/lstm_model.pt'\n",
    "model.load_state_dict(torch.load(model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a983d",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6768c6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "991it [10:26,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pre_list = []\n",
    "highlight_list = []\n",
    "article_list = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_data_loader)):\n",
    "        text, highlight = batch\n",
    "            \n",
    "        text = text.to(device)\n",
    "        highlight = highlight.to(device)\n",
    "\n",
    "        # output = [highlight_len, batch_size, output_dim]\n",
    "\n",
    "        output = model(text, highlight, 0) # turn off teacher forcing\n",
    "\n",
    "        # output = [batch_size, highlight_len, output_dim]\n",
    "        output = output.permute([1,0,2])\n",
    "\n",
    "        batch_size = highlight.shape[0]\n",
    "        for j in range(batch_size):\n",
    "            highlight_text = \"\"\n",
    "            pre_text = \"\"\n",
    "            article = \"\"\n",
    "            for num_high in list(highlight[j]):\n",
    "                highlight_text += text_vocab.lookup_token(num_high)+\" \"\n",
    "            for num_at in list(text[j]):\n",
    "                article += text_vocab.lookup_token(num_at)+\" \"\n",
    "            for num_pre in list(output[j].argmax(1)):\n",
    "                pre_text += text_vocab.lookup_token(num_pre)+\" \"\n",
    "            pre_list.append(pre_text.replace(\"<pad>\", '').replace(\"<bos>\", '').replace(\"<eos>\", ''))\n",
    "            highlight_list.append(highlight_text.replace(\"<pad>\", '').replace(\"<bos>\", '').replace(\"<eos>\", ''))\n",
    "            article_list.append(article.replace(\"<pad>\", '').replace(\"<bos>\", '').replace(\"<eos>\", ''))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0ae1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.tokenize\n",
    "import re\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from bert_score import score\n",
    "\n",
    "# Import test function \n",
    "import test_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a65520e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1982/1982 [00:00<00:00, 4435.96it/s]\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88ede823524467aa76ca4912eb6a8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9f22476f754e438914b380dfb4b438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 67.24 seconds, 29.47 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "test_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "r_1 = 0\n",
    "r_2 = 0\n",
    "n = 2\n",
    "for i in tqdm.tqdm(range(len(pre_list))):\n",
    "    predict_tokens = test_tokenizer.tokenize(pre_list[i])\n",
    "    reference_tokens = test_tokenizer.tokenize(highlight_list[i])\n",
    "    r_1 += test_baseline.rouge_1(predict_tokens, reference_tokens)\n",
    "    r_2 += test_baseline.rouge_n(predict_tokens, reference_tokens, n)\n",
    "    \n",
    "P, R, F1  = score(pre_list, highlight_list, lang = \"en\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebded4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 Score:  1609.4108270775428\n",
      "ROUGE-2 Score:  1609.4108270775428\n"
     ]
    }
   ],
   "source": [
    "print(\"ROUGE-1 Score: \", r_1)\n",
    "print(\"ROUGE-2 Score: \", r_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3d55d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Precision:  tensor(1584.3958)\n",
      "BERT Recall:  tensor(1620.7644)\n",
      "BERT F-1 Score:  tensor(1602.1873)\n"
     ]
    }
   ],
   "source": [
    "print(\"BERT Precision: \", torch.sum(P))\n",
    "print(\"BERT Recall: \", torch.sum(R))\n",
    "print(\"BERT F-1 Score: \", torch.sum(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24a98338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' President Obama , \" the first gay president , \" zig - <unk> on gay marriage over time   .   In 1996 , he endorses same - sex marriage in a survey   .   But in 2011 , a White House adviser says someone else filled out that survey   .   Today , he is the first sitting president to endorse same - sex marriage .  '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_list[145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a92841a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' He has been declared America \\'s \" first gay president . \"   But President Barack Obama \\'s evolution to that title has n\\'t been easy . His positions zig - <unk> over almost two decades .   His advocacy of same - sex marriage began well before his White House years , tracing back to his early political service in Illinois . The effectiveness of his leadership , however , will be determined by the U.S. Supreme Court as it considers a California ban on same - sex marriage .   1996 : While running for the Illinois Senate , Obama signs a questionnaire for a gay Chicago publication saying he favors legalizing same - sex marriages . He later wins the race .   1998 : He alters course and answers \" undecided \" on same - sex marriage when questioned in another survey .   2003 : In his campaign for the Illinois Senate , Obama says in a questionnaire that he is against repealing the Defense of Marriage Act , a 1996 federal law that states for federal purposes , marriage is defined as only between one man and one woman .   2004 : When running for the U.S. Senate , he notes he is \" a Christian \" and that \" marriage is something <unk> between a man and a woman . \" He wins the race .   The new Obama has his heart on his sleeve   2009 : Obama signs a memorandum granting some benefits to same - sex partners of federal employees .   February 2011 : The Obama administration instructs the U.S. Justice Department to stop defending the constitutionality of   the Defense of Marriage Act in court .   June 2011 : White House Communications Director Dan Pfeiffer says President Obama \\'s 1996 questionnaire was \" actually filled out by someone else , not the president . \" Obama \" has been against \" same - sex marriage , but his and the country \\'s position was evolving on the matter , Pfeiffer says . \" I ca n\\'t tell you when that evolution will continue . \"   2012 :   Obama endorses same - sex marriage , the first such statement by a sitting president . The legal decision should be up to the states to determine , he says .   January 2013 : Obama becomes the first U.S. president to mention gays and lesbians in an inaugural address and champions same - sex marriage .   March 2013 : Obama personally reviews and OKs his administration \\'s amicus or \" friend of the court \" brief filed with the U.S. Supreme Court as it weighs the constitutionality of California \\'s 2008 Proposition 8 referendum banning same - sex marriage .   2013 - 2017 : Will Obama \\'s next evolutionary step seek change in the 41 states that currently define marriage as between one man and one woman ? As a second - term president , he certainly has the clout .   Obama on same - sex marriage : Everyone is equal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list[145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051536d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

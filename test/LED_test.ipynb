{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407ea3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk.tokenize\n",
    "import re\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1542d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LEDTokenizer, LongformerTokenizer, LEDForConditionalGeneration\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ebaab",
   "metadata": {},
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe959a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    files= os.listdir(path) \n",
    "    results = {'text':[], 'highlight': [], 'highlight_1':[], 'highlight_2':[], 'highlight_3':[], 'highlight_4':[]}\n",
    "    for file in tqdm.tqdm(files):\n",
    "        if not os.path.isdir(file):\n",
    "            file_name = path + '/'+file\n",
    "            with open(file_name, encoding=\"utf-8\") as f:\n",
    "                text = (f.read()).replace('\\n', \" \").replace(\"(CNN)\", \"\").replace(\"--\", \"\")\n",
    "                if len(text)<1000:\n",
    "                    continue\n",
    "                text_highlights = text.split(\"@highlight\")\n",
    "                final_text = text_highlights[0]\n",
    "                results['text'].append(final_text.strip())\n",
    "                all_highlight = \"\"\n",
    "                for i in range(1, 5):\n",
    "                    key = 'highlight_'+str(i)\n",
    "                    if i<len(text_highlights):\n",
    "                        results[key].append(text_highlights[i])\n",
    "                        all_highlight += text_highlights[i] + '.'\n",
    "                    else:\n",
    "                        results[key].append(\"\")\n",
    "                results['highlight'].append(all_highlight.strip())\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f93092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:01<00:00, 1239.84it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = read_text('test_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6388597d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>highlight</th>\n",
       "      <th>highlight_1</th>\n",
       "      <th>highlight_2</th>\n",
       "      <th>highlight_3</th>\n",
       "      <th>highlight_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wan...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of t...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of...</td>\n",
       "      <td>Obama sends a letter to the heads of the Hou...</td>\n",
       "      <td>Obama to seek congressional approval on mili...</td>\n",
       "      <td>Aim is to determine whether CW were used, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This week the Supreme Court heard two historic...</td>\n",
       "      <td>Ken Klukowski: Cases heard by Supreme Court co...</td>\n",
       "      <td>Ken Klukowski: Cases heard by Supreme Court ...</td>\n",
       "      <td>He says there are questions of whether cases...</td>\n",
       "      <td>If court issues sweeping ruling, it could de...</td>\n",
       "      <td>Klukowski: Gay marriage is such a new phenom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zango Town, Liberia   At the gravesite in a no...</td>\n",
       "      <td>Liberia is one of the countries worst-hit by t...</td>\n",
       "      <td>Liberia is one of the countries worst-hit by...</td>\n",
       "      <td>Entire towns and villages have been placed i...</td>\n",
       "      <td>Health workers must ensure those who die of ...</td>\n",
       "      <td>\"Running away from Ebola is not a solution  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The big winners of this Formula One season cou...</td>\n",
       "      <td>The first race of the 2014 Formula One season ...</td>\n",
       "      <td>The first race of the 2014 Formula One seaso...</td>\n",
       "      <td>Turbo engines are back in the sport, with ea...</td>\n",
       "      <td>Former F1 winner Jody Scheckter expects F1 t...</td>\n",
       "      <td>For the first time in the sport's history, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If that car parked in Harvard Yard is a rockin...</td>\n",
       "      <td>Harvard bans all romantic relationships betwee...</td>\n",
       "      <td>Harvard bans all romantic relationships betw...</td>\n",
       "      <td>Policy comes on heels of investigation into ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>WASHINGTON   The Obama administration is givin...</td>\n",
       "      <td>Departure of General Motors' CEO part of gover...</td>\n",
       "      <td>Departure of General Motors' CEO part of gov...</td>\n",
       "      <td>GM official: White House signaled that \"new ...</td>\n",
       "      <td>Officials: GM to get 60 days of financing; C...</td>\n",
       "      <td>GM, Chrysler were told to prove viability to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>NFL star Adrian Peterson pleaded no contest Tu...</td>\n",
       "      <td>Adrian Peterson says he loves his son and regr...</td>\n",
       "      <td>Adrian Peterson says he loves his son and re...</td>\n",
       "      <td>DA says the NFL star received no special tre...</td>\n",
       "      <td>Peterson is on probation for 2 years, will m...</td>\n",
       "      <td>He is still on the Vikings roster, but has b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>(EW.com)  Moms and Dads: Get your kids to take...</td>\n",
       "      <td>Movie critics have crowned \"The Lego Movie\" as...</td>\n",
       "      <td>Movie critics have crowned \"The Lego Movie\" ...</td>\n",
       "      <td>Reviews are pegging it as a cross between Pi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>The man who made Formula One's bravest comebac...</td>\n",
       "      <td>Niki Lauda says Ferrari has made a \"very good\"...</td>\n",
       "      <td>Niki Lauda says Ferrari has made a \"very goo...</td>\n",
       "      <td>The three-time world champion says it will a...</td>\n",
       "      <td>He warns managing Raikkonen and Alonso in 20...</td>\n",
       "      <td>Lauda says bringing Lewis Hamilton to Merced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>Kabul, Afghanistan   Before dawn on Friday, a ...</td>\n",
       "      <td>NATO forces a target of shooters in Afghan sec...</td>\n",
       "      <td>NATO forces a target of shooters in Afghan s...</td>\n",
       "      <td>They note that there have been five such att...</td>\n",
       "      <td>As NATO withdraws combat troops, advisers wi...</td>\n",
       "      <td>Authors: Problem has grown as Afghans have i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     It's official: U.S. President Barack Obama wan...   \n",
       "1     This week the Supreme Court heard two historic...   \n",
       "2     Zango Town, Liberia   At the gravesite in a no...   \n",
       "3     The big winners of this Formula One season cou...   \n",
       "4     If that car parked in Harvard Yard is a rockin...   \n",
       "...                                                 ...   \n",
       "1977  WASHINGTON   The Obama administration is givin...   \n",
       "1978  NFL star Adrian Peterson pleaded no contest Tu...   \n",
       "1979  (EW.com)  Moms and Dads: Get your kids to take...   \n",
       "1980  The man who made Formula One's bravest comebac...   \n",
       "1981  Kabul, Afghanistan   Before dawn on Friday, a ...   \n",
       "\n",
       "                                              highlight  \\\n",
       "0     Syrian official: Obama climbed to the top of t...   \n",
       "1     Ken Klukowski: Cases heard by Supreme Court co...   \n",
       "2     Liberia is one of the countries worst-hit by t...   \n",
       "3     The first race of the 2014 Formula One season ...   \n",
       "4     Harvard bans all romantic relationships betwee...   \n",
       "...                                                 ...   \n",
       "1977  Departure of General Motors' CEO part of gover...   \n",
       "1978  Adrian Peterson says he loves his son and regr...   \n",
       "1979  Movie critics have crowned \"The Lego Movie\" as...   \n",
       "1980  Niki Lauda says Ferrari has made a \"very good\"...   \n",
       "1981  NATO forces a target of shooters in Afghan sec...   \n",
       "\n",
       "                                            highlight_1  \\\n",
       "0       Syrian official: Obama climbed to the top of...   \n",
       "1       Ken Klukowski: Cases heard by Supreme Court ...   \n",
       "2       Liberia is one of the countries worst-hit by...   \n",
       "3       The first race of the 2014 Formula One seaso...   \n",
       "4       Harvard bans all romantic relationships betw...   \n",
       "...                                                 ...   \n",
       "1977    Departure of General Motors' CEO part of gov...   \n",
       "1978    Adrian Peterson says he loves his son and re...   \n",
       "1979    Movie critics have crowned \"The Lego Movie\" ...   \n",
       "1980    Niki Lauda says Ferrari has made a \"very goo...   \n",
       "1981    NATO forces a target of shooters in Afghan s...   \n",
       "\n",
       "                                            highlight_2  \\\n",
       "0       Obama sends a letter to the heads of the Hou...   \n",
       "1       He says there are questions of whether cases...   \n",
       "2       Entire towns and villages have been placed i...   \n",
       "3       Turbo engines are back in the sport, with ea...   \n",
       "4       Policy comes on heels of investigation into ...   \n",
       "...                                                 ...   \n",
       "1977    GM official: White House signaled that \"new ...   \n",
       "1978    DA says the NFL star received no special tre...   \n",
       "1979    Reviews are pegging it as a cross between Pi...   \n",
       "1980    The three-time world champion says it will a...   \n",
       "1981    They note that there have been five such att...   \n",
       "\n",
       "                                            highlight_3  \\\n",
       "0       Obama to seek congressional approval on mili...   \n",
       "1       If court issues sweeping ruling, it could de...   \n",
       "2       Health workers must ensure those who die of ...   \n",
       "3       Former F1 winner Jody Scheckter expects F1 t...   \n",
       "4                                                         \n",
       "...                                                 ...   \n",
       "1977    Officials: GM to get 60 days of financing; C...   \n",
       "1978    Peterson is on probation for 2 years, will m...   \n",
       "1979                                                      \n",
       "1980    He warns managing Raikkonen and Alonso in 20...   \n",
       "1981    As NATO withdraws combat troops, advisers wi...   \n",
       "\n",
       "                                            highlight_4  \n",
       "0       Aim is to determine whether CW were used, no...  \n",
       "1       Klukowski: Gay marriage is such a new phenom...  \n",
       "2       \"Running away from Ebola is not a solution  ...  \n",
       "3       For the first time in the sport's history, d...  \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "1977    GM, Chrysler were told to prove viability to...  \n",
       "1978    He is still on the Vikings roster, but has b...  \n",
       "1979                                                     \n",
       "1980    Lauda says bringing Lewis Hamilton to Merced...  \n",
       "1981    Authors: Problem has grown as Afghans have i...  \n",
       "\n",
       "[1982 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93823bb",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9918c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd4f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./LED_model/\"\n",
    "\n",
    "generate_model = LEDForConditionalGeneration.from_pretrained(model_dir) \n",
    "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee0cf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEDForConditionalGeneration(\n",
       "  (led): LEDModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): LEDEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): LEDLearnedPositionalEmbedding(2048, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): LEDEncoderLayer(\n",
       "          (self_attn): LEDEncoderAttention(\n",
       "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): LEDDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): LEDLearnedPositionalEmbedding(1024, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): LEDDecoderLayer(\n",
       "          (self_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): LEDDecoderAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1fec0",
   "metadata": {},
   "source": [
    "### Generate Prediction & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170ee307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.tokenize\n",
    "import re\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from bert_score import score\n",
    "\n",
    "# Import test function \n",
    "import test_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15886314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Generation Function\n",
    "\n",
    "def generate_summary(summary_model, text, device):\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length = 1536)\n",
    "    inputid = tokens['input_ids'].to(device)\n",
    "    mask = tokens['attention_mask'].to(device)\n",
    "    pre_ids = summary_model.generate(input_ids = inputid, attention_mask = mask,\n",
    "                                     min_length = 64, max_length = 128)\n",
    "    pre_tokens = tokenizer.decode(pre_ids[0])\n",
    "    return pre_tokens.replace(\"<s>\", '').replace(\"</s>\", '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e2d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1982it [39:43,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get Scores\n",
    "\n",
    "test_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "r_1 = 0\n",
    "r_2 = 0\n",
    "n = 2\n",
    "predict_list = []\n",
    "ref_list = []\n",
    "for index, row in tqdm.tqdm(test_data.iterrows()):\n",
    "    predict = generate_summary(generate_model, row['text'], device)\n",
    "    predict_tokens = test_tokenizer.tokenize(predict)\n",
    "    reference_tokens = test_tokenizer.tokenize(row['highlight'])\n",
    "    predict_list.append(predict)\n",
    "    ref_list.append(row['highlight'])\n",
    "    r_1 += test_baseline.rouge_1(predict_tokens, reference_tokens)\n",
    "    r_2 += test_baseline.rouge_n(predict_tokens, reference_tokens, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c6d66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2077.1114204404357"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e89e4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249.3672524816159"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6615991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a00fa45d8434eebb3099fb3a9cb2414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd55e9f61a348909f87cbd6d28fd8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 28.99 seconds, 68.37 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "P, R, F1  = score(predict_list, ref_list, lang = \"en\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3438f8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1639.0594)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5805a480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1636.1899)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ade36d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1637.5520)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c101f5df",
   "metadata": {},
   "source": [
    "### Generate several exmaples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1c36517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The U.S. Supreme Court rules on a lower court ruling on same-sex marriage .  The ruling was a first legal legal challenge in the state\\'s history of the American community .  The Supreme Court ruled in 2008 that it was a \"great day\" for the ruling. .  The ruling was a \"pantantantant decision\" to end the court\\'s decision.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " generate_summary(generate_model, test_data['text'][772], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8c96307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Five-time world champions Brazil needed to come from two goals down to beat underdogs the United States 3-2 in the final of the Confederations Cup in South Africa on Sunday night.  Brazil celebrated a third Confederations Cup triumph following victories in 2005 and 1997.  Captain Lucio headed an 84th-minute winner to end the hopes of the plucky Americans, who scored twice in the first half-hour in Johannesburg.  Clint Dempsey, who netted in the shock 2-0 win against European champions Spain in the semi-finals, put the U.S. ahead in the 10th minute.  A massive upset seemed to be on the cards when captain Landon Donovan doubled the lead in the 27th minute, but Brazil reduced the deficit just 41 seconds after the half-time break through Luis Fabiano.  The striker then leveled with his fifth goal of the tournament in the 74th minute before Lucio rose highest to ensure that Brazil retained the title.  Brazil went into the game seeking a massive improvement on their dismal showing in laboring to beat hosts South Africa 1-0 in the semi-finals.  But Bob Bradley's U.S. team, beaten 3-0 by Brazil in the group stage, took a shock lead when Dempsey found space in the penalty area to guide home Jonathan Spector's fierce right-wing cross for his third goal of the tournament.  Goalkeeper Tim Howard continued his fine form to keep the Brazilians at bay, then Donovan finished off a superb counter-attack that the South Americans would have been proud of.  The veteran, who earlier in the tournament said his worst footballing memory was a 7-0 drubbing by Brazil when playing for the U.S. under-23 side, set the speedy Charlie Davies free down the left. He then controlled the return pass to cut inside Ramires and slot past Julio Cesar  extending his national goalscoring record to 41.  Howard then saved a low angled shot from Fabiano, then the Sevilla forward headed over the bar 10 minutes before the interval.  But Fabiano struck a killer blow soon after the restart when otherwise-impressive U.S. defender Jay DeMerit allowed him to collect Kaka's pass inside the penalty area and swivel to fire past a helpless Howard.  Brazil surged forward in search of an equalizer, and Real Madrid's new signing Kaka thought he'd scored it when Howard beat out his downward header via the underside of the crossbar while the Everton keeper appeared to be behind the line.  However, the referee ruled otherwise to the Brazilian's disgust, which seemed to be justified by television replays.  Howard denied Fabiano when clear through on goal in the 70th minute, but soon after the forward was on hand to poach the leveler. Kaka beat full-back Spector down the left and his low cross was deflected into the path of Robinho, who prodded the ball against the underside of the bar  and Fabiano headed home the rebound.  With the Americans visibly tiring, it was no surprise when Brazil claimed the winner.  Lucio found space in the box to powerfully head a corner from second-half substitute Elano into the net off the left-hand upright, with the U.S. defense having crucially left the post unguarded.  It was Brazil's third Confederations Cup triumph, having also won in 1997, and represented a 14th victory in the last 15 meetings with the U.S.  Coach Dunga has now presided over seven wins in 20 days, with five at the Confederations Cup and two in World Cup qualifiers.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_data['text'][772]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca80ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409a595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk.tokenize\n",
    "import re\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a438d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LEDTokenizer, LongformerTokenizer, LEDForConditionalGeneration\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f8c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    files= os.listdir(path) \n",
    "    results = {'text':[], 'highlight': [], 'highlight_1':[], 'highlight_2':[], 'highlight_3':[], 'highlight_4':[]}\n",
    "    for file in tqdm.tqdm(files):\n",
    "        if not os.path.isdir(file):\n",
    "            file_name = path + '/'+file\n",
    "            with open(file_name, encoding=\"utf-8\") as f:\n",
    "                text = (f.read()).replace('\\n', \" \").replace(\"(CNN)\", \"\").replace(\"--\", \"\")\n",
    "                if len(text)<1000:\n",
    "                    continue\n",
    "                text_highlights = text.split(\"@highlight\")\n",
    "                final_text = text_highlights[0]\n",
    "                results['text'].append(final_text.strip())\n",
    "                all_highlight = \"\"\n",
    "                for i in range(1, 5):\n",
    "                    key = 'highlight_'+str(i)\n",
    "                    if i<len(text_highlights):\n",
    "                        results[key].append(text_highlights[i])\n",
    "                        all_highlight += text_highlights[i] + '.'\n",
    "                    else:\n",
    "                        results[key].append(\"\")\n",
    "                results['highlight'].append(all_highlight.strip())\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abb607c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 6154.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 40000/40000 [00:06<00:00, 6660.43it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'train_data'\n",
    "test_dir = 'test_data'\n",
    "test_data = read_text(test_dir)\n",
    "train_data = read_text(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c116f906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>highlight</th>\n",
       "      <th>highlight_1</th>\n",
       "      <th>highlight_2</th>\n",
       "      <th>highlight_3</th>\n",
       "      <th>highlight_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wan...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of t...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of...</td>\n",
       "      <td>Obama sends a letter to the heads of the Hou...</td>\n",
       "      <td>Obama to seek congressional approval on mili...</td>\n",
       "      <td>Aim is to determine whether CW were used, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This week the Supreme Court heard two historic...</td>\n",
       "      <td>Ken Klukowski: Cases heard by Supreme Court co...</td>\n",
       "      <td>Ken Klukowski: Cases heard by Supreme Court ...</td>\n",
       "      <td>He says there are questions of whether cases...</td>\n",
       "      <td>If court issues sweeping ruling, it could de...</td>\n",
       "      <td>Klukowski: Gay marriage is such a new phenom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zango Town, Liberia   At the gravesite in a no...</td>\n",
       "      <td>Liberia is one of the countries worst-hit by t...</td>\n",
       "      <td>Liberia is one of the countries worst-hit by...</td>\n",
       "      <td>Entire towns and villages have been placed i...</td>\n",
       "      <td>Health workers must ensure those who die of ...</td>\n",
       "      <td>\"Running away from Ebola is not a solution  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The big winners of this Formula One season cou...</td>\n",
       "      <td>The first race of the 2014 Formula One season ...</td>\n",
       "      <td>The first race of the 2014 Formula One seaso...</td>\n",
       "      <td>Turbo engines are back in the sport, with ea...</td>\n",
       "      <td>Former F1 winner Jody Scheckter expects F1 t...</td>\n",
       "      <td>For the first time in the sport's history, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If that car parked in Harvard Yard is a rockin...</td>\n",
       "      <td>Harvard bans all romantic relationships betwee...</td>\n",
       "      <td>Harvard bans all romantic relationships betw...</td>\n",
       "      <td>Policy comes on heels of investigation into ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>WASHINGTON   The Obama administration is givin...</td>\n",
       "      <td>Departure of General Motors' CEO part of gover...</td>\n",
       "      <td>Departure of General Motors' CEO part of gov...</td>\n",
       "      <td>GM official: White House signaled that \"new ...</td>\n",
       "      <td>Officials: GM to get 60 days of financing; C...</td>\n",
       "      <td>GM, Chrysler were told to prove viability to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>NFL star Adrian Peterson pleaded no contest Tu...</td>\n",
       "      <td>Adrian Peterson says he loves his son and regr...</td>\n",
       "      <td>Adrian Peterson says he loves his son and re...</td>\n",
       "      <td>DA says the NFL star received no special tre...</td>\n",
       "      <td>Peterson is on probation for 2 years, will m...</td>\n",
       "      <td>He is still on the Vikings roster, but has b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>(EW.com)  Moms and Dads: Get your kids to take...</td>\n",
       "      <td>Movie critics have crowned \"The Lego Movie\" as...</td>\n",
       "      <td>Movie critics have crowned \"The Lego Movie\" ...</td>\n",
       "      <td>Reviews are pegging it as a cross between Pi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>The man who made Formula One's bravest comebac...</td>\n",
       "      <td>Niki Lauda says Ferrari has made a \"very good\"...</td>\n",
       "      <td>Niki Lauda says Ferrari has made a \"very goo...</td>\n",
       "      <td>The three-time world champion says it will a...</td>\n",
       "      <td>He warns managing Raikkonen and Alonso in 20...</td>\n",
       "      <td>Lauda says bringing Lewis Hamilton to Merced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>Kabul, Afghanistan   Before dawn on Friday, a ...</td>\n",
       "      <td>NATO forces a target of shooters in Afghan sec...</td>\n",
       "      <td>NATO forces a target of shooters in Afghan s...</td>\n",
       "      <td>They note that there have been five such att...</td>\n",
       "      <td>As NATO withdraws combat troops, advisers wi...</td>\n",
       "      <td>Authors: Problem has grown as Afghans have i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     It's official: U.S. President Barack Obama wan...   \n",
       "1     This week the Supreme Court heard two historic...   \n",
       "2     Zango Town, Liberia   At the gravesite in a no...   \n",
       "3     The big winners of this Formula One season cou...   \n",
       "4     If that car parked in Harvard Yard is a rockin...   \n",
       "...                                                 ...   \n",
       "1977  WASHINGTON   The Obama administration is givin...   \n",
       "1978  NFL star Adrian Peterson pleaded no contest Tu...   \n",
       "1979  (EW.com)  Moms and Dads: Get your kids to take...   \n",
       "1980  The man who made Formula One's bravest comebac...   \n",
       "1981  Kabul, Afghanistan   Before dawn on Friday, a ...   \n",
       "\n",
       "                                              highlight  \\\n",
       "0     Syrian official: Obama climbed to the top of t...   \n",
       "1     Ken Klukowski: Cases heard by Supreme Court co...   \n",
       "2     Liberia is one of the countries worst-hit by t...   \n",
       "3     The first race of the 2014 Formula One season ...   \n",
       "4     Harvard bans all romantic relationships betwee...   \n",
       "...                                                 ...   \n",
       "1977  Departure of General Motors' CEO part of gover...   \n",
       "1978  Adrian Peterson says he loves his son and regr...   \n",
       "1979  Movie critics have crowned \"The Lego Movie\" as...   \n",
       "1980  Niki Lauda says Ferrari has made a \"very good\"...   \n",
       "1981  NATO forces a target of shooters in Afghan sec...   \n",
       "\n",
       "                                            highlight_1  \\\n",
       "0       Syrian official: Obama climbed to the top of...   \n",
       "1       Ken Klukowski: Cases heard by Supreme Court ...   \n",
       "2       Liberia is one of the countries worst-hit by...   \n",
       "3       The first race of the 2014 Formula One seaso...   \n",
       "4       Harvard bans all romantic relationships betw...   \n",
       "...                                                 ...   \n",
       "1977    Departure of General Motors' CEO part of gov...   \n",
       "1978    Adrian Peterson says he loves his son and re...   \n",
       "1979    Movie critics have crowned \"The Lego Movie\" ...   \n",
       "1980    Niki Lauda says Ferrari has made a \"very goo...   \n",
       "1981    NATO forces a target of shooters in Afghan s...   \n",
       "\n",
       "                                            highlight_2  \\\n",
       "0       Obama sends a letter to the heads of the Hou...   \n",
       "1       He says there are questions of whether cases...   \n",
       "2       Entire towns and villages have been placed i...   \n",
       "3       Turbo engines are back in the sport, with ea...   \n",
       "4       Policy comes on heels of investigation into ...   \n",
       "...                                                 ...   \n",
       "1977    GM official: White House signaled that \"new ...   \n",
       "1978    DA says the NFL star received no special tre...   \n",
       "1979    Reviews are pegging it as a cross between Pi...   \n",
       "1980    The three-time world champion says it will a...   \n",
       "1981    They note that there have been five such att...   \n",
       "\n",
       "                                            highlight_3  \\\n",
       "0       Obama to seek congressional approval on mili...   \n",
       "1       If court issues sweeping ruling, it could de...   \n",
       "2       Health workers must ensure those who die of ...   \n",
       "3       Former F1 winner Jody Scheckter expects F1 t...   \n",
       "4                                                         \n",
       "...                                                 ...   \n",
       "1977    Officials: GM to get 60 days of financing; C...   \n",
       "1978    Peterson is on probation for 2 years, will m...   \n",
       "1979                                                      \n",
       "1980    He warns managing Raikkonen and Alonso in 20...   \n",
       "1981    As NATO withdraws combat troops, advisers wi...   \n",
       "\n",
       "                                            highlight_4  \n",
       "0       Aim is to determine whether CW were used, no...  \n",
       "1       Klukowski: Gay marriage is such a new phenom...  \n",
       "2       \"Running away from Ebola is not a solution  ...  \n",
       "3       For the first time in the sport's history, d...  \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "1977    GM, Chrysler were told to prove viability to...  \n",
       "1978    He is still on the Vikings roster, but has b...  \n",
       "1979                                                     \n",
       "1980    Lauda says bringing Lewis Hamilton to Merced...  \n",
       "1981    Authors: Problem has grown as Afghans have i...  \n",
       "\n",
       "[1982 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "971e51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a907e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = list(train_data[\"text\"])\n",
    "y_train = list(train_data[\"highlight\"])\n",
    "\n",
    "x_test= list(test_data[\"text\"])\n",
    "y_test = list(test_data[\"highlight\"])\n",
    "\n",
    "x_train_tokenized = tokenizer(x_train, padding=True, truncation=True, return_tensors=\"pt\", max_length = 1536)\n",
    "y_train_tokenized = tokenizer(y_train, padding=True, truncation=True, return_tensors=\"pt\", max_length = 256)\n",
    "x_test_tokenized = tokenizer(x_test, padding=True, truncation=True, return_tensors=\"pt\", max_length = 1536)\n",
    "y_test_tokenized = tokenizer(y_test, padding=True, truncation=True, return_tensors=\"pt\", max_length = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "681ccc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6321175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.input_ids = encodings.input_ids\n",
    "        self.attention_mask = encodings.attention_mask\n",
    "        result = []\n",
    "        for label in labels.input_ids:\n",
    "            tmp =list(label)\n",
    "            result.append([-100 if token_id == tokenizer.pad_token_id else token_id for token_id in label])\n",
    "        self.labels = result\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        item[\"input_ids\"] = self.input_ids[idx]\n",
    "        item[\"attention_mask\"] = self.attention_mask[idx]\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b453a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(x_train_tokenized, y_train_tokenized)\n",
    "test_dataset = Dataset(x_test_tokenized, y_test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e032e0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'LED_dataset/train_dataset.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3728/1364499823.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"LED_dataset/train_dataset.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"LED_dataset/test_dataset.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'LED_dataset/train_dataset.pth'"
     ]
    }
   ],
   "source": [
    "torch.save(train_dataset, \"LED_dataset/train_dataset.pth\")\n",
    "torch.save(test_dataset, \"LED_dataset/test_dataset.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4ebf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

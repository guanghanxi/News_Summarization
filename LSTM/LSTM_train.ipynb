{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c487177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk.tokenize\n",
    "import re\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c430c3e",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8977213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pack_sequence, pad_packed_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b793f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    text_data = []\n",
    "    target_data = []\n",
    "    for unit in data:\n",
    "        text_data.append(torch.tensor(unit[0]))\n",
    "        target_data.append(torch.tensor(unit[1]))\n",
    "    text = pad_sequence(text_data, batch_first=True)\n",
    "    target = pad_sequence(target_data, batch_first=True)\n",
    "    return text, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cf71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.load('train_data_loader.pth')\n",
    "test_data_loader = torch.load('test_data_loader.pth')\n",
    "text_vocab = torch.load('text_vocab.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f168b9",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb23c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, dec_hidden_dim, num_layers,dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_dim=input_dim\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.num_layers=num_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, dec_hidden_dim)\n",
    "\n",
    "        self.layer=nn.LSTM(input_size=emb_dim,hidden_size=hidden_dim, \\\n",
    "                        num_layers=num_layers,batch_first=True, \\\n",
    "                        dropout=dropout,bidirectional=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(x))     \n",
    "        \n",
    "        out,(hidden,c)=self.layer(embedded)\n",
    "        \n",
    "        s = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
    "        \n",
    "        return out, s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb55de",
   "metadata": {},
   "source": [
    "Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9337e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        # [size(h_t)+size(s_{t-1}), dec_hid_dim]\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim, bias=False)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, s, enc_output):\n",
    "        # s = [batch_size, dec_hid_dim]\n",
    "        # enc_output = [batch_size, src_len, enc_hid_dim * 2]\n",
    "\n",
    "        batch_size = enc_output.shape[0]\n",
    "        src_len = enc_output.shape[1]\n",
    "\n",
    "        # repeat decoder hidden state src_len times\n",
    "        # s = [batch_size, src_len, enc_hid_dim * 2]\n",
    "        # enc_output = [batch_size, src_len, enc_hid_dim * 2]\n",
    "        s = s.unsqueeze(1).repeat(1, src_len, 1)\n",
    "\n",
    "        # energy = [batch_size, src_len, dec_hid_dim]\n",
    "        energy = torch.tanh(self.attn(torch.cat((s, enc_output), dim=2)))\n",
    "\n",
    "        # attention = [batch_size, src_len]\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec77278",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention, device):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.device = device\n",
    "        \n",
    "        self.layer=nn.LSTM(input_size=enc_hid_dim * 2 + emb_dim, hidden_size=dec_hid_dim, \\\n",
    "                        num_layers=1,batch_first=True, \\\n",
    "                        dropout=dropout,bidirectional=False)\n",
    "        \n",
    "        self.fc_out = nn.Linear(enc_hid_dim * 2 + dec_hid_dim + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, dec_input, s, enc_output):\n",
    "        # dec_input = [batch_size]\n",
    "        # s = [batch_size, dec_hid_dim]\n",
    "        # enc_output = [src_len, batch_size, enc_hid_dim *2]\n",
    "        \n",
    "        batch_size = dec_input.shape[0]\n",
    "\n",
    "        # dec_input = [batch_size,1]\n",
    "        dec_input = dec_input.unsqueeze(1)\n",
    "\n",
    "        # embedded = [batch_size, 1, emb_dim]\n",
    "        embedded = self.dropout(self.embedding(dec_input))\n",
    "\n",
    "        # s = [batch_size, dec_hid_dim]\n",
    "        # enc_output = [batch_size, src_len, enc_hid_dim *2]\n",
    "\n",
    "        # a = [batch_size, 1, src_len]\n",
    "        a = self.attention(s, enc_output).unsqueeze(1)\n",
    "\n",
    "        # c = [batch_size, 1, enc_hid_dim * 2]\n",
    "        c = torch.bmm(a, enc_output)\n",
    "\n",
    "        # lstm_input = [batch_size, 1, (enc_hid_dim*2) + emb_dim]\n",
    "        lstm_input = torch.cat((embedded, c), dim=2)\n",
    "        \n",
    "        c0 = torch.randn(1, batch_size, self.dec_hid_dim).to(self.device)\n",
    "\n",
    "        # dec_output = [batch_size, src_len(=1), dec_hid_dim]\n",
    "        # dec_hidden = [n_layers*num_directions, batch_size, dec_hid_dim]\n",
    "        dec_output, (dec_hidden, _) = self.layer(lstm_input, (s.unsqueeze(0), c0))\n",
    "\n",
    "        # embedded = [batch_size, emb_dim]\n",
    "        # dec_output = [batch_size, dec_hid_dim]\n",
    "        # c = [batch_size, enc_hid_dim * 2]\n",
    "        embedded = embedded.squeeze(1)\n",
    "        dec_output = dec_output.squeeze(1)\n",
    "        c = c.squeeze(1)\n",
    "\n",
    "        # pred = [batch_size, output_dim]\n",
    "        pred = self.fc_out(torch.cat((dec_output, c, embedded), dim=1))\n",
    "\n",
    "        return pred, dec_hidden.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dbbf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src = [batch_size, text_length]\n",
    "        # trg = [batch_size, summarizarion_length]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing (scheduled sampling)\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, vocab_size).to(self.device)\n",
    "\n",
    "        # enc_output : [src_len, batch_size, enc_hid_dim * 2]\n",
    "        # s : [batch_size, dec_hid_dim]\n",
    "        enc_output, s = self.encoder(src)\n",
    "\n",
    "        # first input to the decoder is the <bob> tokens\n",
    "        dec_input = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            dec_output, s = self.decoder(dec_input, s, enc_output)\n",
    "\n",
    "            outputs[t] = dec_output\n",
    "\n",
    "            # decide if using teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # get the highest predicted token from predictions\n",
    "            prediction = dec_output.argmax(1)\n",
    "\n",
    "            # if teacher forcing, use actural next token as input\n",
    "            # if not, use predicted token\n",
    "            dec_input = trg[:, t] if teacher_force else prediction\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf6f27ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guanghax/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Define Hyper parameter\n",
    "\n",
    "INPUT_DIM = len(text_vocab)\n",
    "OUTPUT_DIM = len(text_vocab)\n",
    "ENC_EMB_DIM = 300\n",
    "DEC_EMB_DIM = 300\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, 2, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn, device)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9881d",
   "metadata": {},
   "source": [
    "### Option: Initialize Model with the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_glove= GloVe()\n",
    "pretained_embedding = my_glove.get_vecs_by_tokens(text_vocab.get_itos())\n",
    "pretained_embedding = pretained_embedding.to(device)\n",
    "enc.embedding.weight.data = pretained_embedding\n",
    "dec.embedding.weight.data = pretained_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6059eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretained_embedding = pretained_embedding.to(device)\n",
    "enc.embedding.weight.data = pretained_embedding\n",
    "dec.embedding.weight.data = pretained_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852602b9",
   "metadata": {},
   "source": [
    "### Option: Reload a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e3bcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = 'model/3/lstm_model.pt'\n",
    "model.load_state_dict(torch.load(model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a983d",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3a2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train function\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, batch in tqdm.tqdm(enumerate(iterator)):\n",
    "        text, highlight = batch \n",
    "        \n",
    "        text = text.to(device)\n",
    "        highlight = highlight.to(device)\n",
    "\n",
    "        # pred = [highlight_len, batch_size, pred_dim]\n",
    "        pred = model(text, highlight)\n",
    "        pred_dim = pred.shape[-1]\n",
    "\n",
    "        # highlight = [highlight_len*batch_size]\n",
    "        # pred = [highlight_len*batch_size]\n",
    "        highlight = highlight.view(-1)\n",
    "        pred = pred.permute([1,0,2]).contiguous().view(-1, pred_dim)\n",
    "\n",
    "        loss = criterion(pred, highlight)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if i%500 == 0 and i!=0:\n",
    "            print(train_loss/500)\n",
    "            train_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f947ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation function\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm.tqdm(enumerate(iterator)):\n",
    "            text, highlight = batch\n",
    "            \n",
    "            text = text.to(device)\n",
    "            highlight = highlight.to(device)\n",
    "\n",
    "            # output = [highlight_len, batch_size, output_dim]\n",
    "            output = model(text, highlight, 0) # turn off teacher forcing\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            # trg = [highlight_len*batch_size]\n",
    "            # output = [highlight_len*batch_size, output_dim]\n",
    "            output = output.permute([1,0,2]).contiguous().view(-1, output_dim)\n",
    "            highlight = highlight.view(-1)\n",
    "\n",
    "            loss = criterion(output, highlight)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07133fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [07:45,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.219203948974609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [15:28,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.276841556549072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [23:10,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.235005108833313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [30:57,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.265779499530792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [38:45,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.279764371395111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [46:22,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2363659567832945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3501it [54:07,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2297070064544675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [1:01:53,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.225161261558533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4501it [1:09:41,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.207482703685761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [1:17:25,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.210640722751617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5501it [1:25:16,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.199427905559539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [1:33:03,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.211570686817169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6501it [1:40:43,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.167676355361938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [1:48:29,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1602605438232425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7501it [1:56:11,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1262509484291074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [2:03:56,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.143068867683411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8501it [2:11:45,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.128458675384522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [2:19:37,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.126866454124451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9501it [2:27:28,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.089778331756592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [2:35:17,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.10336150598526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10501it [2:43:02,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.128002324581146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11001it [2:50:50,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.10438598203659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11045it [2:51:31,  1.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ebee42977e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-40286e9589c9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# pred = [highlight_len, batch_size, pred_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mpred_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1971a9b04d03>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-52245b426bfd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dec_input, s, enc_output)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mlstm_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_hid_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# dec_output = [batch_size, src_len(=1), dec_hid_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    train(model, train_data_loader, optimizer, criterion)\n",
    "    print(evaluate(model, test_data_loader, criterion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42bc4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/4/lstm_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e96fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
